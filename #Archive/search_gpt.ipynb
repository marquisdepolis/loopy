{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: googlesearch-python in /Users/rohit/Library/Python/3.9/lib/python/site-packages (1.1.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.9.3 in /Users/rohit/Library/Python/3.9/lib/python/site-packages (from googlesearch-python) (4.9.3)\n",
      "Requirement already satisfied: requests==2.25.1 in /Users/rohit/Library/Python/3.9/lib/python/site-packages (from googlesearch-python) (2.25.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/rohit/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4==4.9.3->googlesearch-python) (2.3.2.post1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/rohit/Library/Python/3.9/lib/python/site-packages (from requests==2.25.1->googlesearch-python) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rohit/Library/Python/3.9/lib/python/site-packages (from requests==2.25.1->googlesearch-python) (2022.12.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/rohit/Library/Python/3.9/lib/python/site-packages (from requests==2.25.1->googlesearch-python) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rohit/Library/Python/3.9/lib/python/site-packages (from requests==2.25.1->googlesearch-python) (1.26.14)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in /Users/rohit/Library/Python/3.9/lib/python/site-packages (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rohit/Library/Python/3.9/lib/python/site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rohit/Library/Python/3.9/lib/python/site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/rohit/Library/Python/3.9/lib/python/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/rohit/Library/Python/3.9/lib/python/site-packages (from requests) (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install googlesearch-python\n",
    "from googlesearch import search\n",
    "import openai\n",
    "!pip install requests\n",
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Financial Statement\n",
      "2. S&P 500\n",
      "3. Insurance Company\n",
      "4. Stock-Based Compensation\n",
      "5. Analysis\n",
      "6. Best Ways\n",
      "\"What are the best ways to read a financial statement for an S&P 500 insurance company to analyse stock based compensation?\"\n"
     ]
    }
   ],
   "source": [
    "your_question = input(\"Input what you are curious about: \")\n",
    "\n",
    "with open(\"openai_api_key.txt\", \"r\") as f:\n",
    "    openai.api_key = f.read().strip()\n",
    "\n",
    "query1 = []\n",
    "\n",
    "google_it = f\"What are the key terms you can extract from this query that, if searched, will help find the answers to {your_question}\"\n",
    "model1 = \"text-davinci-003\"\n",
    "params1 = {\n",
    "    \"prompt\": google_it,\n",
    "    \"temperature\": 0.5,\n",
    "    \"max_tokens\": 100,\n",
    "    \"top_p\": 1,\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"presence_penalty\": 0\n",
    "}\n",
    "\n",
    "query1 = openai.Completion.create(engine=model1, **params1)\n",
    "print(query1.choices[0].text.strip())\n",
    "\n",
    "google_it = f\"Return exactly one Google search query, phrased as a question, I could Google to find information regarding {your_question}\"\n",
    "model1 = \"text-davinci-003\"\n",
    "params1 = {\n",
    "    \"prompt\": google_it,\n",
    "    \"temperature\": 0.5,\n",
    "    \"max_tokens\": 100,\n",
    "    \"top_p\": 1,\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"presence_penalty\": 0\n",
    "}\n",
    "\n",
    "query2 = openai.Completion.create(engine=model1, **params1)\n",
    "print(query2.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"What are the best ways to read a financial statement for an S&P 500 insurance company to analyse stock based compensation?\"'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = query2.choices[0].text.strip()\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyASjpYvuBFNcDmfNVIsLlT0_LK_aB7vaV0\n",
      "71ba39c784b6f44ad\n",
      "Page number isn't specified, defaulting to 1\n",
      "https://customsearch.googleapis.com/customsearch/v1?cx=71ba39c784b6f44ad&key=AIzaSyASjpYvuBFNcDmfNVIsLlT0_LK_aB7vaV0&q=-f&start=1\n",
      "None\n",
      "No search results found\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m     exit()\n\u001b[1;32m     43\u001b[0m \u001b[39m# iterate over 10 results found\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[39mfor\u001b[39;00m i, search_item \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39;49m(search_items, start\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m):\n\u001b[1;32m     45\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         long_description \u001b[39m=\u001b[39m search_item[\u001b[39m\"\u001b[39m\u001b[39mpagemap\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmetatags\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mog:description\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Iterate over the search results and append each URL to the list\n",
    "# programmatically search Google\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "def open_file(filepath):\n",
    "    with open(filepath, 'r', encoding='latin-1') as infile:\n",
    "        return infile.read()\n",
    "os.chdir('/Users/rohit/Library/CloudStorage/OneDrive-Personal/SM_RK Shared folder/Coding_Analysis/gpt_search')\n",
    "\n",
    "# API KEY from: https://developers.google.com/custom-search/v1/overview\n",
    "API_KEY = open_file('/Users/rohit/Library/CloudStorage/OneDrive-Personal/SM_RK Shared folder/Coding_Analysis/gpt_search/google_api_key.txt')\n",
    "# get your Search Engine ID on your CSE control panel\n",
    "SEARCH_ENGINE_ID = open_file('/Users/rohit/Library/CloudStorage/OneDrive-Personal/SM_RK Shared folder/Coding_Analysis/gpt_search/google_searchengine_id.txt')\n",
    "print(API_KEY)\n",
    "print(SEARCH_ENGINE_ID)\n",
    "try:\n",
    "    query = sys.argv[1]\n",
    "except:\n",
    "    print(\"Please specify a search query\")\n",
    "    exit()\n",
    "try:\n",
    "    page = int(sys.argv[2])\n",
    "    # make sure page is positive\n",
    "    assert page > 0\n",
    "except:\n",
    "    print(\"Page number isn't specified, defaulting to 1\")\n",
    "    page = 1\n",
    "# constructing the URL\n",
    "# doc: https://developers.google.com/custom-search/v1/using_rest\n",
    "# calculating start, (page=2) => (start=11), (page=3) => (start=21)\n",
    "start = (page - 1) * 10 + 1\n",
    "url = f\"https://customsearch.googleapis.com/customsearch/v1?cx={SEARCH_ENGINE_ID}&key={API_KEY}&q={query}&start={start}\"\n",
    "print(url)\n",
    "# make the API request\n",
    "data = requests.get(url).json()\n",
    "# get the result items\n",
    "search_items = data.get(\"items\")\n",
    "print(search_items)\n",
    "if search_items is None:\n",
    "    print(\"No search results found\")\n",
    "    exit()\n",
    "# iterate over 10 results found\n",
    "for i, search_item in enumerate(search_items, start=1):\n",
    "    try:\n",
    "        long_description = search_item[\"pagemap\"][\"metatags\"][0][\"og:description\"]\n",
    "    except KeyError:\n",
    "        long_description = \"N/A\"\n",
    "    # get the page title\n",
    "    title = search_item.get(\"title\")\n",
    "    # page snippet\n",
    "    snippet = search_item.get(\"snippet\")\n",
    "    # alternatively, you can get the HTML snippet (bolded keywords)\n",
    "    html_snippet = search_item.get(\"htmlSnippet\")\n",
    "    # extract the page url\n",
    "    link = search_item.get(\"link\")\n",
    "    # print the results\n",
    "    print(\"=\"*10, f\"Result #{i+start-1}\", \"=\"*10)\n",
    "    print(\"Title:\", title)\n",
    "    print(\"Description:\", snippet)\n",
    "    print(\"Long description:\", long_description)\n",
    "    print(\"URL:\", link, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through the urls to get the summarised answer\n",
    "answer = []\n",
    "\n",
    "for x in range(num_results):\n",
    "    # Get the page content\n",
    "    html = requests.get(links[x]).text\n",
    "\n",
    "    # Extract the page title and text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    title = soup.title.string\n",
    "    text = \"\\n\".join([p.text for p in soup.find_all(\"p\")])\n",
    "\n",
    "    # Set up the GPT-3 API request\n",
    "    request = f\"Please summarize the following article:\\nTitle: {title}\\n\\n{text[:4000]}\"\n",
    "    model = \"text-davinci-003\"\n",
    "    params = {\n",
    "        \"prompt\": request,\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 100,\n",
    "        \"top_p\": 1,\n",
    "        \"frequency_penalty\": 0,\n",
    "        \"presence_penalty\": 0\n",
    "    }\n",
    "\n",
    "    # Call the GPT-3 API and print the response\n",
    "    response = openai.Completion.create(engine=model, **params)\n",
    "    summary = response.choices[0].text.strip()\n",
    "    answer.append(summary)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this line if you are no longer going to run the script, as it takes longer to boot up again next time.\n",
    "gateway.shutdown() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
